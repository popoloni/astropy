#!/usr/bin/env python3
"""
Complete System Test
Tests both CLI and mobile app interfaces for telescope analysis
"""

import sys
import os
import subprocess
import json
from typing import List, Dict

# Add paths for imports
root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, root_dir)
sys.path.insert(0, os.path.join(root_dir, 'mobile_app'))

# Test imports
try:
    from analysis.telescope_analysis import (
        get_telescope_database, calculate_exposure_recommendation,
        calculate_quality_metrics, TargetType
    )
    print("‚úÖ Common analysis functions imported successfully")
except ImportError as e:
    print(f"‚ùå Failed to import common analysis functions: {e}")
    sys.exit(1)

try:
    from mobile_app.utils.smart_scopes import (
        get_scope_manager, get_exposure_calculator, get_quality_predictor
    )
    print("‚úÖ Mobile app functions imported successfully")
except ImportError as e:
    print(f"‚ùå Failed to import mobile app functions: {e}")
    sys.exit(1)


class SystemTester:
    """Comprehensive system tester"""
    
    def __init__(self):
        self.test_results = []
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.cli_script = os.path.join(root_dir, "wrappers", "run_telescope_analysis.py")
    
    def run_test(self, test_name: str, test_func) -> bool:
        """Run a test and record results"""
        try:
            print(f"\nüß™ Testing: {test_name}")
            result = test_func()
            if result:
                print(f"‚úÖ {test_name}: PASSED")
                self.test_results.append((test_name, True, None))
                return True
            else:
                print(f"‚ùå {test_name}: FAILED")
                self.test_results.append((test_name, False, "Test returned False"))
                return False
        except Exception as e:
            print(f"‚ùå {test_name}: ERROR - {e}")
            self.test_results.append((test_name, False, str(e)))
            return False
    
    def test_common_functions(self) -> bool:
        """Test common analysis functions"""
        # Test database access
        database = get_telescope_database()
        if len(database) != 8:
            return False
        
        # Test exposure calculation
        exposure = calculate_exposure_recommendation(
            telescope_id="seestar_s50",
            target_type=TargetType.GALAXY,
            target_magnitude=10.0
        )
        if not exposure or exposure.single_exposure_sec <= 0:
            return False
        
        # Test quality prediction
        quality = calculate_quality_metrics(
            telescope_id="vespera_pro",
            target_type=TargetType.EMISSION_NEBULA,
            target_magnitude=9.0
        )
        if not quality or quality.overall_score <= 0:
            return False
        
        return True
    
    def test_mobile_app_functions(self) -> bool:
        """Test mobile app wrapper functions"""
        # Test scope manager
        scope_manager = get_scope_manager()
        scopes = scope_manager.get_all_scopes()
        if len(scopes) != 8:
            return False
        
        # Test setting selected scope
        if not scope_manager.set_selected_scope("dwarf_3"):
            return False
        
        selected = scope_manager.get_selected_scope()
        if not selected or selected.name != "Dwarf III":
            return False
        
        # Test exposure calculator
        exposure_calc = get_exposure_calculator()
        exposure = exposure_calc.calculate_exposure(
            scope=selected,
            target_type=TargetType.PLANETARY_NEBULA,
            target_magnitude=8.5
        )
        if not exposure or exposure.single_exposure_sec <= 0:
            return False
        
        # Test quality predictor
        quality_pred = get_quality_predictor()
        quality = quality_pred.predict_quality(
            scope=selected,
            target_type=TargetType.GALAXY,
            target_magnitude=10.5
        )
        if not quality or quality.overall_score <= 0:
            return False
        
        return True
    
    def test_cli_interface(self) -> bool:
        """Test CLI interface"""
        # Test list command
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        result = subprocess.run([
            sys.executable, self.cli_script, "list"
        ], capture_output=True, text=True, cwd=root_dir)
        
        if result.returncode != 0:
            return False
        
        if "Seestar S50" not in result.stdout:
            return False
        
        # Test analyze command
        result = subprocess.run([
            sys.executable, self.cli_script, "analyze", "vespera_2"
        ], capture_output=True, text=True, cwd=root_dir)
        
        if result.returncode != 0:
            return False
        
        if "Vespera II" not in result.stdout:
            return False
        
        # Test exposure command
        result = subprocess.run([
            sys.executable, self.cli_script, "exposure", "seestar_s30", "galaxy",
            "--magnitude", "9.5", "--pollution", "dark"
        ], capture_output=True, text=True, cwd=root_dir)
        
        if result.returncode != 0:
            return False
        
        if "Single Exposure:" not in result.stdout:
            return False
        
        # Test quality command
        result = subprocess.run([
            sys.executable, self.cli_script, "quality", "dwarf_2", "emission_nebula",
            "--magnitude", "8.0", "--size", "45"
        ], capture_output=True, text=True, cwd=root_dir)
        
        if result.returncode != 0:
            return False
        
        if "Overall Score:" not in result.stdout:
            return False
        
        # Test compare command
        result = subprocess.run([
            sys.executable, self.cli_script, "compare", "planetary_nebula",
            "--magnitude", "10.0", "--size", "30"
        ], capture_output=True, text=True, cwd=root_dir)
        
        if result.returncode != 0:
            return False
        
        if "Rankings" not in result.stdout:
            return False
        
        return True
    
    def test_data_export(self) -> bool:
        """Test data export functionality"""
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        # Test CLI export
        result = subprocess.run([
            sys.executable, self.cli_script, "export", "--filename", "test_export.json"
        ], capture_output=True, text=True, cwd=root_dir)
        
        if result.returncode != 0:
            return False
        
        # Check if file was created
        export_file = os.path.join(root_dir, "test_export.json")
        if not os.path.exists(export_file):
            return False
        
        # Validate JSON content
        try:
            with open(export_file, 'r') as f:
                data = json.load(f)
            
            if len(data) != 8:
                return False
            
            if "seestar_s50" not in data:
                return False
            
            # Clean up
            os.remove(export_file)
            
        except (json.JSONDecodeError, KeyError):
            return False
        
        return True
    
    def test_mobile_app_integration(self) -> bool:
        """Test mobile app integration tests"""
        # Run existing mobile app tests
        root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        test_files = [
            os.path.join(root_dir, "mobile_app", "test_all_scope_configurations.py"),
            os.path.join(root_dir, "mobile_app", "test_exposure_quality_system.py")
        ]
        
        for test_file in test_files:
            if os.path.exists(test_file):
                result = subprocess.run([
                    sys.executable, test_file
                ], capture_output=True, text=True, cwd=root_dir)
                
                # Accept exit code 1 if the test shows mostly working status
                if result.returncode != 0 and "WORKING" not in result.stdout:
                    print(f"Mobile app test failed: {test_file}")
                    print(f"Error: {result.stderr}")
                    return False
                
                # Check for success indicators in output
                success_indicators = ["FULLY OPERATIONAL", "WORKING", "PASSED", "‚úÖ"]
                has_success = any(indicator in result.stdout for indicator in success_indicators)
                
                if not has_success:
                    print(f"Mobile app test output doesn't indicate success: {test_file}")
                    print(f"Output: {result.stdout[-200:]}")  # Show last 200 chars
                    return False
        
        return True
    
    def test_cross_platform_compatibility(self) -> bool:
        """Test that both CLI and mobile app use same data"""
        # Get data from common functions
        common_database = get_telescope_database()
        
        # Get data from mobile app
        scope_manager = get_scope_manager()
        mobile_database = scope_manager.get_all_scopes()
        
        # Compare databases
        if len(common_database) != len(mobile_database):
            return False
        
        for scope_id in common_database:
            if scope_id not in mobile_database:
                return False
            
            common_scope = common_database[scope_id]
            mobile_scope = mobile_database[scope_id]
            
            if common_scope.name != mobile_scope.name:
                return False
            
            if common_scope.aperture_mm != mobile_scope.aperture_mm:
                return False
        
        return True
    
    def run_all_tests(self):
        """Run all tests"""
        print("üöÄ STARTING COMPREHENSIVE SYSTEM TEST")
        print("=" * 60)
        
        tests = [
            ("Common Analysis Functions", self.test_common_functions),
            ("Mobile App Functions", self.test_mobile_app_functions),
            ("CLI Interface", self.test_cli_interface),
            ("Data Export", self.test_data_export),
            ("Mobile App Integration", self.test_mobile_app_integration),
            ("Cross-Platform Compatibility", self.test_cross_platform_compatibility)
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            if self.run_test(test_name, test_func):
                passed += 1
        
        print("\n" + "=" * 60)
        print("üìä TEST SUMMARY")
        print("=" * 60)
        
        for test_name, success, error in self.test_results:
            status = "‚úÖ PASSED" if success else "‚ùå FAILED"
            print(f"{status}: {test_name}")
            if error:
                print(f"   Error: {error}")
        
        print(f"\nüéØ Results: {passed}/{total} tests passed")
        
        if passed == total:
            print("üéâ ALL TESTS PASSED! System is fully operational.")
            return True
        else:
            print("‚ö†Ô∏è  Some tests failed. Please review the issues above.")
            return False


def main():
    """Main test runner"""
    tester = SystemTester()
    success = tester.run_all_tests()
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()